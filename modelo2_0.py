# -*- coding: utf-8 -*-
"""modelo1.0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Q93ZcLgW37wIvAVj6oiF6ItY-ZJmf27R
"""

# streamlit_app.py

import streamlit as st
from PIL import Image
import numpy as np

try:
    import tensorflow as tf
    st.success("‚úÖ TensorFlow instalado com sucesso!")
    st.write(f"Vers√£o do TensorFlow: {tf.__version__}")
except ImportError:
    st.error("‚ùå TensorFlow n√£o est√° instalado. Verifique requirements.txt.")
    st.write("Bibliotecas instaladas:", sys.executable)
    st.stop()  # Interrompe o app se faltar TensorFlow

import tflite_runtime.interpreter as tflite
interpreter = tflite.Interpreter(model_path="modelo.tflite")  # Converta antes para .tflite

# Definindo o tamanho que o modelo espera
IMG_SIZE = (150, 150)  # Atualize se seu modelo usar outro tamanho

# Definindo as classes
class_names = ['adenocarcinoma de c√≥lon', 'adenocarcinoma de pulm√£o', 'adenocarcinoma escamoso', 'c√©lulas normais']

# T√≠tulo do app
st.title("Classificador de C√¢ncer de Pulm√£o e C√≥lon ü´Åüß¨")

st.write(
    """
    Este aplicativo classifica imagens de tecidos em diferentes tipos de c√¢ncer ou tecido normal.
    Fa√ßa upload de uma imagem para ver a predi√ß√£o do modelo.
    """
)

# Upload de imagem
uploaded_file = st.file_uploader("/content/lungaca98.jpeg", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    image = Image.open(uploaded_file).convert('RGB')
    st.image(image, caption='Imagem enviada', use_column_width=True)

    # Pr√©-processamento
    img_array = np.array(image.resize(IMG_SIZE)) / 255.0
    img_array = np.expand_dims(img_array, axis=0)  # Adiciona batch dimension

    # Predi√ß√£o
    prediction = model.predict(img_array)
    predicted_class = class_names[np.argmax(prediction)]

    st.subheader('Resultado:')
    st.success(f'Predi√ß√£o: {predicted_class}')

!pip install flask

from flask import Flask, request, jsonify
import tensorflow as tf
import numpy as np

# Cria a inst√¢ncia do app Flask
app = Flask(__name__)

# Carrega o modelo
model_path = '/content/Model.h5'
model = tf.keras.models.load_model(model_path)

# Define a rota para a predi√ß√£o
@app.route('/predict', methods=['POST'])
def predict():
    # Extrai os dados da requisi√ß√£o
    data = request.get_json(force=True)
    input_data = np.array(data['input_data'])

    # Realiza a predi√ß√£o
    prediction = model.predict(input_data)

    # Retorna a predi√ß√£o como JSON
    return jsonify({'prediction': prediction.tolist()})

# Inicia o servidor
if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)

from flask import Flask, request, jsonify
import tensorflow as tf
import numpy as np

# Cria a inst√¢ncia do app Flask
app = Flask(__name__)

# Carrega o modelo
model_path = '/content/Model.h5'
# ensure the model is loaded correctly and not overwritten
model = tf.keras.models.load_model(model_path) # this line was the issue

# Define a rota para a predi√ß√£o
@app.route('/predict', methods=['POST'])
def predict():
    # Extrai os dados da requisi√ß√£o
    data = request.get_json(force=True)
    input_data = np.array(data['input_data'])

    # Realiza a predi√ß√£o
    prediction = model.predict(input_data)

    # Retorna a predi√ß√£o como JSON
    return jsonify({'prediction': prediction.tolist()})

# Inicia o servidor
if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)